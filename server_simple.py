#!/usr/bin/env python3
"""
BreastAI WebSocket Server v3.3.0 - SIMPLE ET DIRECT
Serveur WebSocket minimaliste pour contrÃ´ler l'entraÃ®nement depuis l'interface web
"""

import os
import sys
import json
import asyncio
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, Set

import websockets
from websockets.server import WebSocketServerProtocol

# Importer notre systÃ¨me d'entraÃ®nement
from breastai_training import TrainingSystem, Config

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('logs/server.log')
    ]
)
logger = logging.getLogger(__name__)

# ==================================================================================
# SERVEUR WEBSOCKET
# ==================================================================================

class BreastAIServer:
    """Serveur WebSocket simple pour BreastAI"""
    
    def __init__(self, host: str = 'localhost', port: int = 8765):
        self.host = host
        self.port = port
        self.clients: Set[WebSocketServerProtocol] = set()
        self.training_system: Optional[TrainingSystem] = None
        self.training_task: Optional[asyncio.Task] = None
        self.is_training = False
        
        logger.info(f"Serveur initialisÃ© sur {host}:{port}")
    
    async def broadcast(self, message: Dict):
        """Envoie un message Ã  tous les clients connectÃ©s - VERSION PRODUCTION"""
        if not self.clients:
            logger.warning(f"ðŸš¨ AUCUN CLIENT CONNECTÃ‰ pour {message['type']}")  # IMPORTANT !
            return
        
        try:
            message_json = json.dumps(message, ensure_ascii=False)
        except Exception as e:
            logger.error(f"Erreur sÃ©rialisation JSON: {e}")
            return
        
        # Copie pour Ã©viter les erreurs d'itÃ©ration
        clients_copy = self.clients.copy()
        disconnected = set()
        
        for client in clients_copy:
            try:
                await client.send(message_json)
            except Exception as e:
                logger.warning(f"ðŸš¨ CLIENT DÃ‰CONNECTÃ‰: {e}")  # VISIBLE !
                disconnected.add(client)
        
        # Nettoyage silencieux
        self.clients -= disconnected
    
    async def handle_client(self, websocket: WebSocketServerProtocol):
        """GÃ¨re une connexion client"""
        self.clients.add(websocket)
        client_addr = websocket.remote_address
        logger.info(f"Client connectÃ©: {client_addr}")
        
        try:
            # Message de bienvenue
            await websocket.send(json.dumps({
                'type': 'connection_established',
                'message': 'ConnectÃ© au serveur BreastAI',
                'timestamp': datetime.now().isoformat()
            }))
            
            # KEEP-ALIVE PRODUCTION - Simple et efficace
            async def keep_alive():
                try:
                    while websocket in self.clients:
                        await asyncio.sleep(20)  # Ping optimal toutes les 20s
                        if websocket in self.clients:
                            await websocket.ping()
                except:
                    pass  # Fin silencieuse
            
            asyncio.create_task(keep_alive())
            
            # Boucle de rÃ©ception
            async for message in websocket:
                await self.handle_message(websocket, message)
        
        except websockets.exceptions.ConnectionClosed:
            logger.info(f"Client dÃ©connectÃ©: {client_addr}")
        except Exception as e:
            logger.error(f"Erreur client {client_addr}: {e}", exc_info=True)
        finally:
            self.clients.discard(websocket)
    
    async def handle_message(self, websocket: WebSocketServerProtocol, message: str):
        """Traite un message reÃ§u"""
        try:
            data = json.loads(message)
            msg_type = data.get('type')
            
            logger.info(f"Message reÃ§u: {msg_type}")
            
            if msg_type == 'start_training':
                # L'interface envoie {type: 'start_training', config: {...}} ou directement les params
                config = data.get('config', data)  # Supporter les deux formats
                await self.start_training(config)
            
            elif msg_type == 'stop_training':
                await self.stop_training()
            
            elif msg_type == 'get_status':
                await self.send_status(websocket)
            
            elif msg_type == 'list_checkpoints':
                await self.list_checkpoints()
            
            elif msg_type == 'load_checkpoint':
                checkpoint = data.get('checkpoint')
                await self.load_checkpoint(checkpoint)
            
            elif msg_type == 'resume_training':
                checkpoint = data.get('checkpoint')
                epochs = data.get('epochs')
                await self.resume_training(checkpoint, epochs)
            
            elif msg_type == 'delete_checkpoint':
                checkpoint = data.get('checkpoint')
                await self.delete_checkpoint(checkpoint)
            
            elif msg_type == 'export_onnx':
                await self.export_onnx(data)
            
            elif msg_type == 'system_diagnostics':
                await self.system_diagnostics()
            
            elif msg_type == 'ping':
                await websocket.send(json.dumps({'type': 'pong'}))
            
            else:
                logger.warning(f"Type de message inconnu: {msg_type}")
        
        except json.JSONDecodeError:
            logger.error("Message JSON invalide")
        except Exception as e:
            logger.error(f"Erreur traitement message: {e}", exc_info=True)
            await self.broadcast({
                'type': 'error',
                'message': f'Erreur serveur: {str(e)}'
            })
    
    async def start_training(self, config_data: Dict):
        """DÃ©marre un nouvel entraÃ®nement"""
        if self.is_training:
            await self.broadcast({
                'type': 'error',
                'message': 'EntraÃ®nement dÃ©jÃ  en cours'
            })
            return
        
        try:
            logger.info("DÃ©marrage d'un nouvel entraÃ®nement")
            
            # Mapper la config de l'interface
            mapped_config = self._map_interface_config(config_data)
            
            # CrÃ©er le systÃ¨me d'entraÃ®nement
            config = Config(mapped_config)
            self.training_system = TrainingSystem(config, callback=self.broadcast)
            
            # Setup
            success = await self.training_system.setup()
            if not success:
                await self.broadcast({
                    'type': 'error',
                    'message': 'Ã‰chec de l\'initialisation'
                })
                return
            
            # Lancer l'entraÃ®nement en arriÃ¨re-plan
            self.is_training = True
            epochs = config_data.get('epochs', 50)
            
            # Stocker la task pour pouvoir la cancel
            self.training_task = asyncio.create_task(self._run_training(epochs))
            
            logger.info(f"EntraÃ®nement lancÃ©: {epochs} epochs")
        
        except Exception as e:
            logger.error(f"Erreur start_training: {e}", exc_info=True)
            await self.broadcast({
                'type': 'error',
                'message': f'Erreur dÃ©marrage: {str(e)}'
            })
            self.is_training = False
    
    async def _run_training(self, epochs: int):
        """ExÃ©cute l'entraÃ®nement"""
        try:
            logger.info(f"=== DEBUT TRAINING {epochs} epochs ===")  # DEBUG
            await self.training_system.train(epochs)
            logger.info("=== FIN TRAINING NORMALE ===")  # DEBUG
        except Exception as e:
            logger.error(f"CRASH SERVEUR - TRAINING: {type(e).__name__}: {e}", exc_info=True)
            await self.broadcast({
                'type': 'error',
                'message': f'Erreur entraÃ®nement: {str(e)}'
            })
        finally:
            self.is_training = False
            self.training_system = None
    
    async def stop_training(self):
        """ArrÃªte l'entraÃ®nement en cours"""
        if not self.is_training or self.training_system is None:
            await self.broadcast({
                'type': 'error',
                'message': 'Aucun entraÃ®nement en cours'
            })
            return
        
        logger.info("ArrÃªt de l'entraÃ®nement demandÃ©")
        
        # ArrÃªter le systÃ¨me
        await self.training_system.stop()
        
        # Cancel la task si elle existe
        if self.training_task and not self.training_task.done():
            self.training_task.cancel()
            try:
                await self.training_task
            except asyncio.CancelledError:
                logger.info("Training task cancelled")
    
    async def send_status(self, websocket: WebSocketServerProtocol):
        """Envoie le statut actuel"""
        status = {
            'type': 'status',
            'is_training': self.is_training,
            'clients_connected': len(self.clients),
            'timestamp': datetime.now().isoformat()
        }
        await websocket.send(json.dumps(status))
    
    async def list_checkpoints(self):
        """Liste les checkpoints disponibles avec mÃ©tadonnÃ©es"""
        try:
            import torch
            
            checkpoint_dir = Path('checkpoints')
            if not checkpoint_dir.exists():
                await self.broadcast({
                    'type': 'checkpoints_list',
                    'checkpoints': []
                })
                return
            
            checkpoints = []
            for ckpt_file in checkpoint_dir.glob('*.pth'):
                try:
                    stat = ckpt_file.stat()
                    
                    # Essayer de charger les mÃ©tadonnÃ©es
                    try:
                        ckpt_data = torch.load(ckpt_file, map_location='cpu')
                        epoch = ckpt_data.get('epoch', 0)
                        accuracy = ckpt_data.get('best_val_acc', 0.0)
                        architecture = ckpt_data.get('architecture', 'unknown')
                        timestamp = ckpt_data.get('timestamp', '')
                    except Exception:
                        # Si Ã©chec lecture mÃ©tadonnÃ©es, valeurs par dÃ©faut
                        epoch = 0
                        accuracy = 0.0
                        architecture = 'unknown'
                        timestamp = ''
                    
                    checkpoints.append({
                        'filename': ckpt_file.name,
                        'path': str(ckpt_file),
                        'size': stat.st_size,
                        'created': datetime.fromtimestamp(stat.st_ctime).isoformat(),
                        'epoch': epoch,
                        'accuracy': float(accuracy),
                        'architecture': architecture,
                        'type': 'best' if 'best' in ckpt_file.name else 'periodic',
                        'timestamp': timestamp
                    })
                except Exception as e:
                    logger.warning(f"Erreur lecture checkpoint {ckpt_file}: {e}")
            
            # Trier par date (plus rÃ©cent d'abord)
            checkpoints.sort(key=lambda x: x['created'], reverse=True)
            
            await self.broadcast({
                'type': 'checkpoints_list',
                'checkpoints': checkpoints
            })
            
            logger.info(f"Liste de {len(checkpoints)} checkpoints envoyÃ©e")
            
        except Exception as e:
            logger.error(f"Erreur list_checkpoints: {e}", exc_info=True)
            await self.broadcast({
                'type': 'error',
                'message': f'Erreur liste checkpoints: {str(e)}'
            })
    
    async def load_checkpoint(self, checkpoint_path: str):
        """Charge un checkpoint et initialise pour reprendre l'entraÃ®nement"""
        try:
            await self.broadcast({
                'type': 'log',
                'message': f'Chargement checkpoint: {checkpoint_path}',
                'level': 'info'
            })
            
            # Charger les mÃ©tadonnÃ©es du checkpoint
            import torch
            checkpoint_data = torch.load(checkpoint_path, map_location='cpu')
            
            # RÃ©cupÃ©rer la config du checkpoint
            saved_config = checkpoint_data.get('config', {})
            
            await self.broadcast({
                'type': 'log',
                'message': f'Checkpoint epoch {checkpoint_data.get("epoch", 0)}, accuracy {checkpoint_data.get("best_val_acc", 0):.2f}%',
                'level': 'info'
            })
            
            # CrÃ©er le systÃ¨me d'entraÃ®nement avec la config sauvegardÃ©e
            from breastai_training import Config, TrainingSystem
            config = Config(saved_config)
            self.training_system = TrainingSystem(config, callback=self.broadcast)
            
            # Setup
            await self.broadcast({
                'type': 'log',
                'message': 'Initialisation du systÃ¨me...',
                'level': 'info'
            })
            
            success = await self.training_system.setup()
            
            if not success:
                raise ValueError("Ã‰chec du setup")
            
            # Charger le checkpoint
            start_epoch = self.training_system.load_checkpoint(checkpoint_path)
            
            if start_epoch is None:
                raise ValueError("Ã‰chec du chargement du checkpoint")
            
            await self.broadcast({
                'type': 'checkpoint_loaded',
                'checkpoint': checkpoint_path,
                'start_epoch': start_epoch + 1,  # Reprendre Ã  l'epoch suivante
                'best_val_acc': self.training_system.best_val_acc,
                'message': f'PrÃªt Ã  reprendre depuis epoch {start_epoch + 1}',
                'timestamp': datetime.now().isoformat()
            })
            
            logger.info(f"Checkpoint chargÃ© avec succÃ¨s: epoch {start_epoch}")
            
        except Exception as e:
            logger.error(f"Erreur load_checkpoint: {e}", exc_info=True)
            await self.broadcast({
                'type': 'error',
                'message': f'Erreur chargement checkpoint: {str(e)}'
            })
            self.training_system = None
    
    async def resume_training(self, checkpoint_path: str, epochs: Optional[int] = None):
        """Reprend l'entraÃ®nement depuis un checkpoint"""
        try:
            import torch
            
            if self.is_training:
                await self.broadcast({
                    'type': 'error',
                    'message': 'EntraÃ®nement dÃ©jÃ  en cours'
                })
                return
            
            # D'abord charger le checkpoint
            await self.load_checkpoint(checkpoint_path)
            
            if not self.training_system:
                raise ValueError("SystÃ¨me d'entraÃ®nement non initialisÃ©")
            
            # RÃ©cupÃ©rer l'epoch de dÃ©part
            checkpoint_data = torch.load(checkpoint_path, map_location='cpu')
            start_epoch = checkpoint_data.get('epoch', 0) + 1
            
            # Nombre d'epochs total (si pas spÃ©cifiÃ©, continuer jusqu'au max configurÃ©)
            if epochs is None:
                epochs = self.training_system.config.get('training', 'epochs', default=50)
            
            await self.broadcast({
                'type': 'log',
                'message': f'Reprise entraÃ®nement epoch {start_epoch} â†’ {epochs}',
                'level': 'info'
            })
            
            # Lancer l'entraÃ®nement
            self.is_training = True
            self.training_task = asyncio.create_task(
                self.training_system.train(epochs=epochs, start_epoch=start_epoch)
            )
            
            logger.info(f"EntraÃ®nement repris depuis epoch {start_epoch}")
            
        except Exception as e:
            logger.error(f"Erreur resume_training: {e}", exc_info=True)
            await self.broadcast({
                'type': 'error',
                'message': f'Erreur reprise: {str(e)}'
            })
            self.is_training = False
    
    async def delete_checkpoint(self, checkpoint: str):
        """Supprime un checkpoint"""
        try:
            ckpt_path = Path(checkpoint)
            if ckpt_path.exists():
                ckpt_path.unlink()
                await self.broadcast({
                    'type': 'log',
                    'message': f'Checkpoint supprimÃ©: {checkpoint}',
                    'level': 'success'
                })
                # Renvoyer la liste mise Ã  jour
                await self.list_checkpoints()
            else:
                await self.broadcast({
                    'type': 'error',
                    'message': f'Checkpoint introuvable: {checkpoint}'
                })
        except Exception as e:
            logger.error(f"Erreur delete_checkpoint: {e}", exc_info=True)
            await self.broadcast({
                'type': 'error',
                'message': f'Erreur suppression: {str(e)}'
            })
    
    async def export_onnx(self, data: Dict):
        """Exporte le modÃ¨le en ONNX"""
        try:
            checkpoint_path = data.get('checkpoint')
            
            if not self.training_system:
                # Besoin de crÃ©er un systÃ¨me temporaire pour l'export
                await self.broadcast({
                    'type': 'log',
                    'message': 'Initialisation pour export...',
                    'level': 'info'
                })
                
                # Config minimale
                from breastai_training import Config, TrainingSystem
                config = Config()
                temp_system = TrainingSystem(config, callback=self.broadcast)
                
                # Setup du modÃ¨le
                await temp_system.setup()
                
                # Export
                success = await temp_system.export_onnx(checkpoint_path)
                
            else:
                # Utiliser le systÃ¨me existant
                success = await self.training_system.export_onnx(checkpoint_path)
            
            if success:
                logger.info("Export ONNX rÃ©ussi")
            else:
                logger.error("Export ONNX Ã©chouÃ©")
                
        except Exception as e:
            logger.error(f"Erreur export_onnx: {e}", exc_info=True)
            await self.broadcast({
                'type': 'error',
                'message': f'Erreur export: {str(e)}'
            })
    
    async def system_diagnostics(self):
        """Renvoie les diagnostics systÃ¨me"""
        import psutil
        
        try:
            diagnostics = {
                'type': 'system_diagnostics',
                'cpu_percent': psutil.cpu_percent(interval=1),
                'memory_percent': psutil.virtual_memory().percent,
                'memory_used_gb': psutil.virtual_memory().used / (1024**3),
                'memory_total_gb': psutil.virtual_memory().total / (1024**3),
                'disk_percent': psutil.disk_usage('/').percent,
                'timestamp': datetime.now().isoformat()
            }
            
            await self.broadcast(diagnostics)
            logger.info("Diagnostics systÃ¨me envoyÃ©s")
            
        except Exception as e:
            logger.error(f"Erreur system_diagnostics: {e}", exc_info=True)
            await self.broadcast({
                'type': 'error',
                'message': f'Erreur diagnostics: {str(e)}'
            })
    
    def _map_interface_config(self, interface_config: Dict) -> Dict:
        """Mappe la config de l'interface vers notre structure"""
        config = {
            'paths': {
                'data_dir': interface_config.get('data_path', 'data'),
                'checkpoint_dir': interface_config.get('checkpoint_path', 'checkpoints')
            },
            'training': {
                'epochs': interface_config.get('epochs', 50),
                'learning_rate': interface_config.get('learning_rate', 0.0003),
                'weight_decay': interface_config.get('weight_decay', 0.0001),
                'optimizer': interface_config.get('optimizer', 'adamw'),
                'scheduler': interface_config.get('scheduler', 'cosine'),
                'label_smoothing': interface_config.get('label_smoothing', 0.1),
                'gradient_clip': interface_config.get('gradient_clip', 1.0),
                # ðŸ†• Features avancÃ©es depuis interface
                'use_ema': interface_config.get('use_ema', False),
                'ema_decay': interface_config.get('ema_decay', 0.9998),
                'focal_loss': {
                    'enabled': interface_config.get('use_focal_loss', False),
                    'alpha': interface_config.get('focal_loss_alpha', [0.25, 0.50, 0.25]),
                    'gamma': interface_config.get('focal_loss_gamma', 2.5)
                }
            },
            'data': {
                'batch_size': interface_config.get('batch_size', 4),
                'num_workers': interface_config.get('num_workers', 4),
                'image_size': interface_config.get('image_size', 512),
                'gradient_accumulation_steps': interface_config.get('gradient_accumulation_steps', 1),
                'augmentation': {
                    'horizontal_flip': interface_config.get('horizontal_flip', 0.5),
                    'vertical_flip': interface_config.get('vertical_flip', 0.3),
                    'rotation': interface_config.get('rotation', 15),
                    'brightness': interface_config.get('brightness', 0.2),
                    'contrast': interface_config.get('contrast', 0.2)
                }
            },
            'inference': {
                'tta_enabled': interface_config.get('use_tta', False)
            },
            'model': {
                'architecture': interface_config.get('model_name', 'efficientnetv2_s'),
                'num_classes': interface_config.get('num_classes', 3),
                'use_cbam': interface_config.get('use_cbam', True),
                'dropout_rate': interface_config.get('dropout_rate', 0.4),
                'pretrained': interface_config.get('pretrained', True),
                'progressive_unfreezing': {
                    'phase1_epochs': interface_config.get('progressive_unfreezing_phase1', 8),
                    'phase2_epochs': interface_config.get('progressive_unfreezing_phase2', 20),
                    'phase3_epochs': interface_config.get('progressive_unfreezing_phase3', 40)
                }
            }
        }
        
        # Log la config reÃ§ue
        logger.info(f"Config mappÃ©e: model={config['model']['architecture']}, "
                   f"epochs={config['training']['epochs']}, "
                   f"batch={config['data']['batch_size']}, "
                   f"lr={config['training']['learning_rate']}")
        
        return config
    
    async def start(self):
        """DÃ©marre le serveur"""
        logger.info("="*80)
        logger.info("BREASTAI WEBSOCKET SERVER v3.3.0 - SIMPLIFIE")
        logger.info(f"DÃ©marrage sur ws://{self.host}:{self.port}")
        logger.info("="*80)
        
        async with websockets.serve(self.handle_client, self.host, self.port):
            logger.info("Serveur prÃªt! En attente de connexions...")
            await asyncio.Future()  # Run forever

# ==================================================================================
# POINT D'ENTRÃ‰E
# ==================================================================================

async def main():
    # CrÃ©er les dossiers nÃ©cessaires
    Path('logs').mkdir(exist_ok=True)
    Path('checkpoints').mkdir(exist_ok=True)
    
    # DÃ©marrer le serveur
    server = BreastAIServer(host='localhost', port=8765)
    await server.start()

if __name__ == '__main__':
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("\nServeur arrÃªtÃ© par l'utilisateur")
    except Exception as e:
        logger.error(f"Erreur fatale: {e}", exc_info=True)
