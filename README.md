# ğŸ§  BreastAI Studio v3.3

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Status: Production](https://img.shields.io/badge/Status-Production-green.svg)]()

> ğŸ¥ **SystÃ¨me d'intelligence artificielle de pointe pour le diagnostic du cancer du sein**  
> Architecture: **EfficientNetV2 + CBAM** | Interface Web Moderne | EntraÃ®nement en Temps RÃ©el

---

## âœ¨ FonctionnalitÃ©s Principales

### ğŸ¯ CapacitÃ©s IA
- **Architecture avancÃ©e** : EfficientNetV2 (S/M/L) avec module d'attention CBAM
- **Classification 3 classes** : Normal, BÃ©nin, Malin
- **EntraÃ®nement optimisÃ©** : Mixed Precision, Gradient Accumulation, Label Smoothing
- **Augmentation donnÃ©es** : Rotations, flips, ajustements colorimÃ©triques
- **Schedulers avancÃ©s** : Cosine Annealing, ReduceLROnPlateau, OneCycle

### ğŸ–¥ï¸ Interface Web Moderne
- âš¡ **Temps rÃ©el** : WebSocket pour suivi live de l'entraÃ®nement
- ğŸ“Š **Dashboard interactif** : MÃ©triques, graphiques, progression par batch
- ğŸ’» **Console logs** : Affichage complet de tous les Ã©vÃ©nements
- ğŸ’¾ **Gestion checkpoints** : Reprise, export ONNX, suppression
- âš™ï¸ **Configuration flexible** : Tous les hyperparamÃ¨tres ajustables

### ğŸš€ Production Ready
- ğŸ“¦ **Export ONNX** : DÃ©ploiement multi-plateforme
- ğŸ”„ **Resume training** : Reprise depuis n'importe quel checkpoint
- ğŸ“ **Logging complet** : Logs fichiers + console + interface
- ğŸ›¡ï¸ **Gestion erreurs** : Skip des batchs corrompus automatique
- ğŸ”“ **Progressive Unfreezing** : Optimisation CPU (Ã—3-4 plus rapide au dÃ©but)

---

## ğŸ“‹ PrÃ©requis

```bash
Python 3.10+
PyTorch 2.0+
CUDA 11.8+ (recommandÃ© pour GPU)
8GB RAM minimum (16GB recommandÃ©)
```

---

## ğŸš€ Installation Rapide

### 1ï¸âƒ£ Cloner le projet
```bash
git clone https://github.com/votre-username/project_breast_ai.git
cd project_breast_ai
```

### 2ï¸âƒ£ CrÃ©er l'environnement virtuel
```bash
python -m venv venv_breastai
```

**Windows:**
```bash
venv_breastai\Scripts\activate
```

**Linux/Mac:**
```bash
source venv_breastai/bin/activate
```

### 3ï¸âƒ£ Installer les dÃ©pendances
```bash
pip install -r requirements.txt
```

---

## ğŸ“Š Structure des DonnÃ©es

Le projet attend une structure de donnÃ©es spÃ©cifique :

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ normal/      # Images normales
â”‚   â”œâ”€â”€ begin/       # Tumeurs bÃ©nignes
â”‚   â””â”€â”€ malignant/   # Tumeurs malignes
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ benign/
â”‚   â””â”€â”€ malignant/
â””â”€â”€ test/
    â”œâ”€â”€ Benign/
    â””â”€â”€ Malignant/
```

> âš ï¸ **Note**: Les donnÃ©es ne sont PAS incluses dans ce repo (trop volumineuses).  
> Placez vos datasets dans le dossier `data/` selon la structure ci-dessus.

---

## ğŸ® Utilisation

### Mode Interface Web (RecommandÃ©)

#### 1ï¸âƒ£ DÃ©marrer le serveur WebSocket
```bash
python server_simple.py
```

#### 2ï¸âƒ£ Ouvrir l'interface
Ouvrez `frontend/app.html` dans votre navigateur

#### 3ï¸âƒ£ Utiliser l'interface
1. **Connecter** au serveur
2. **Configurer** les hyperparamÃ¨tres
3. **DÃ©marrer** l'entraÃ®nement
4. **Suivre** en temps rÃ©el dans le dashboard et la console

### Mode CLI (AvancÃ©)

```python
from breastai_training import TrainingSystem, Config

# Configuration
config = Config({
    'model': {
        'architecture': 'efficientnetv2_s',
        'num_classes': 3,
        'use_cbam': True
    },
    'training': {
        'epochs': 50,
        'learning_rate': 0.0003,
        'optimizer': 'adamw'
    }
})

# Lancer l'entraÃ®nement
system = TrainingSystem(config)
await system.setup()
await system.train(epochs=50)
```

---

## ğŸ“ˆ FonctionnalitÃ©s DÃ©taillÃ©es

### ğŸ›ï¸ HyperparamÃ¨tres Configurables

| ParamÃ¨tre | Options | Description |
|-----------|---------|-------------|
| **ModÃ¨le** | efficientnetv2_s/m/l, efficientnet_b4 | Architecture du rÃ©seau |
| **Epochs** | 1-200 | Nombre d'Ã©poques |
| **Batch Size** | 1-32 | Taille des batchs |
| **Learning Rate** | 0.00001-0.01 | Taux d'apprentissage |
| **Optimizer** | AdamW, Adam, SGD | Optimiseur |
| **Scheduler** | Cosine, ReduceLR, OneCycle | Scheduler LR |
| **CBAM** | ActivÃ©/DÃ©sactivÃ© | Module d'attention |
| **Dropout** | 0.0-0.8 | Taux de dropout |

### ğŸ“Š MÃ©triques Suivies

- **Loss** : Train & Validation
- **Accuracy** : Train & Validation  
- **F1-Score** : Macro & Weighted
- **Learning Rate** : Ã‰volution en temps rÃ©el
- **Batch Progress** : DÃ©tails par batch

### ğŸ’¾ Checkpoints

- **Automatique** : Sauvegarde du meilleur modÃ¨le
- **PÃ©riodique** : Tous les 10 epochs
- **MÃ©tadonnÃ©es** : Epoch, accuracy, config complÃ¨te
- **Reprise** : Continue depuis n'importe quel checkpoint

### ğŸ“¦ Export ONNX

```python
# Via l'interface : Bouton "Export ONNX"
# Ou en CLI :
await system.export_onnx('checkpoints/best_model.pth')
```

---

## ğŸ—ï¸ Architecture Technique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Frontend (app.html)                    â”‚
â”‚              Interface Web Moderne + WebSocket           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ ws://localhost:8765
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Server WebSocket (server_simple.py)         â”‚
â”‚          Gestion connexions + Broadcast messages         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ async/await
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Training System (breastai_training.py)           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  EfficientNetV2 + CBAM                          â”‚   â”‚
â”‚   â”‚  â”œâ”€â”€ Feature Extraction (Pretrained)            â”‚   â”‚
â”‚   â”‚  â”œâ”€â”€ CBAM Attention Module                      â”‚   â”‚
â”‚   â”‚  â””â”€â”€ Classification Head (3 classes)            â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                           â”‚
â”‚   â€¢ DataLoaders (Train/Val/Test)                        â”‚
â”‚   â€¢ Optimizer + Scheduler                                â”‚
â”‚   â€¢ Mixed Precision Training                             â”‚
â”‚   â€¢ Checkpoint Management                                â”‚
â”‚   â€¢ ONNX Export                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Structure du Projet

```
project_breast_ai/
â”œâ”€â”€ ğŸ§  CORE
â”‚   â”œâ”€â”€ breastai_training.py    # SystÃ¨me d'entraÃ®nement
â”‚   â”œâ”€â”€ server_simple.py        # Serveur WebSocket
â”‚   â””â”€â”€ inference_onnx.py       # InfÃ©rence ONNX
â”‚
â”œâ”€â”€ ğŸ¨ FRONTEND
â”‚   â”œâ”€â”€ app.html               # Interface web v3.3
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ğŸ“ DATA (non inclus)
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â”‚
â”œâ”€â”€ ğŸ’¾ OUTPUTS (gÃ©nÃ©rÃ©)
â”‚   â”œâ”€â”€ checkpoints/           # ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ exports/onnx/          # Exports ONNX
â”‚   â””â”€â”€ logs/                  # Logs d'entraÃ®nement
â”‚
â”œâ”€â”€ ğŸ“š DOCUMENTATION
â”‚   â”œâ”€â”€ QUICK_START_FR.md      # DÃ©marrage rapide
â”‚   â”œâ”€â”€ GUIDE_INTERFACE_FR.md  # Guide interface
â”‚   â””â”€â”€ CHANGELOG_FR.md        # Historique
â”‚
â””â”€â”€ âš™ï¸ CONFIG
    â”œâ”€â”€ config.json            # Configuration par dÃ©faut
    â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
    â””â”€â”€ .gitignore            # Exclusions Git
```

---

## âš¡ Progressive Unfreezing (Optimisation CPU)

**Nouvelle fonctionnalitÃ© v3.3.1** : AccÃ©lÃ©ration massive de l'entraÃ®nement sur CPU !

### ğŸ“Š Comment Ã§a marche ?

Le **Progressive Unfreezing** gÃ¨le progressivement les couches du backbone prÃ©-entraÃ®nÃ© pour accÃ©lÃ©rer drastiquement l'entraÃ®nement, surtout sur CPU.

```
ğŸ”’ Phase 1 (Epochs 1-5)   : Backbone gelÃ© â†’ Classifier seul
                            âœ… Ã—3-4 plus rapide
                            ğŸ“‰ ~5% des paramÃ¨tres entraÃ®nÃ©s

ğŸ”“ Phase 2 (Epochs 6-15)  : DÃ©gel partiel â†’ 3 derniers blocs
                            âœ… Ã—2 plus rapide
                            ğŸ“‰ ~30% des paramÃ¨tres entraÃ®nÃ©s

ğŸ”¥ Phase 3 (Epochs 16+)   : DÃ©gel complet â†’ Tous les paramÃ¨tres
                            âš™ï¸ Vitesse normale
                            ğŸ“ˆ 100% des paramÃ¨tres entraÃ®nÃ©s
```

### ğŸ’¡ Gain estimÃ©

| Configuration | Sans PU | Avec PU | Gain |
|---------------|---------|---------|------|
| **CPU (53k images)** | ~220 jours | ~70-90 jours | **Ã—2.5-3** |
| **GPU (53k images)** | ~2-3 jours | ~1.5-2 jours | **Ã—1.3-1.5** |

> **Note** : Le Progressive Unfreezing est activÃ© **automatiquement** ! Aucune configuration nÃ©cessaire.

---

## ğŸ¯ Performance

### Configuration RecommandÃ©e

| Composant | RecommandÃ© | Minimum |
|-----------|-----------|---------|
| **GPU** | NVIDIA RTX 3060+ (12GB) | GTX 1660 (6GB) |
| **RAM** | 16GB | 8GB |
| **CPU** | 8 cores | 4 cores |
| **Storage** | SSD 50GB | HDD 50GB |

### Benchmarks (Exemple)

- **EfficientNetV2-S** : ~95% Val Accuracy, ~30min/epoch (RTX 3060)
- **EfficientNetV2-M** : ~96% Val Accuracy, ~45min/epoch (RTX 3060)
- **EfficientNetV2-L** : ~97% Val Accuracy, ~60min/epoch (RTX 3060)

> ğŸ“Š RÃ©sultats dÃ©pendent fortement de votre dataset

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. Fork le projet
2. CrÃ©ez une branche (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

---

## ğŸ“ Changelog

### v3.3.1 (Actuel - 2024-09-30)
- ğŸ”“ **Progressive Unfreezing** : AccÃ©lÃ©ration massive pour CPU (Ã—2.5-3)
- ğŸ® **Auto-dÃ©tection GPU** : Bascule automatique GPU/CPU
- âš¡ **Logs temps rÃ©el** : Affichage Ã  chaque batch
- ğŸ“Š **Statistiques dÃ©taillÃ©es** : Comptage paramÃ¨tres entraÃ®nables
- ğŸ› **Fix** : Correction device CPU forcÃ©

### v3.3.0 (2024-09-29)
- ğŸ¨ **Interface moderne** : Dashboard amÃ©liorÃ©
- ğŸ”§ **Optimisations** : Performance et stabilitÃ©
- ğŸ› **Corrections** : Gestion erreurs amÃ©liorÃ©e

Voir [CHANGELOG_FR.md](CHANGELOG_FR.md) pour l'historique complet.

---

## ğŸ“„ License

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ™ Remerciements

- **PyTorch** pour le framework deep learning
- **EfficientNet** pour l'architecture de base
- **CBAM** pour le module d'attention
- La communautÃ© open-source

---

## ğŸ“§ Contact & Support

Pour toute question ou support :
- ğŸ› **Issues** : [Sabrsl](https://github.com/votre-username/project_breast_ai/issues)

---

<div align="center">

**DÃ©veloppÃ© avec â¤ï¸ pour amÃ©liorer le diagnostic du cancer du sein**

â­ Si ce projet vous est utile, donnez-lui une Ã©toile !

</div>
